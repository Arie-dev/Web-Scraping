{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully as books_data_silver_20241106.csv in bucket 'silver'.\n",
      "Data saved successfully as quotes_data_silver_20241106.csv in bucket 'silver'.\n",
      "Data saved successfully as books_data_gold_20241106.csv in bucket 'gold'.\n",
      "Data saved successfully as quotes_data_gold_20241106.csv in bucket 'gold'.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from minio import Minio\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from io import StringIO\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def setup_minio_client():\n",
    "    minio_client = Minio('localhost:9000',\n",
    "                         access_key='ROOTUSER',\n",
    "                         secret_key='DATAINCUBATOR',\n",
    "                         secure=False)\n",
    "    # Create bronze bucket if it doesn't exist\n",
    "    if not minio_client.bucket_exists('bronze'):\n",
    "        minio_client.make_bucket('bronze')\n",
    "        print(\"Bucket 'bronze' created successfully\")\n",
    "    # Create silver bucket if it doesn't exist\n",
    "    if not minio_client.bucket_exists('silver'):\n",
    "        minio_client.make_bucket('silver')\n",
    "        print(\"Bucket 'silver' created successfully\")\n",
    "    # Create gold bucket if it doesn't exist\n",
    "    if not minio_client.bucket_exists('gold'):\n",
    "        minio_client.make_bucket('gold')\n",
    "        print(\"Bucket 'gold' created successfully\")\n",
    "    \n",
    "    return minio_client\n",
    "\n",
    "minio_client = setup_minio_client()\n",
    "\n",
    "def scrape_books_data():\n",
    "    url = \"https://books.toscrape.com/catalogue/page-1.html\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        book_rows = soup.find_all('article', class_='product_pod')  \n",
    "        \n",
    "        books_data = []\n",
    "        for book in book_rows:\n",
    "            title = book.find('h3').find('a')['title']\n",
    "            price = book.find('p', class_='price_color').text.strip()\n",
    "            availability = book.find('p', class_='instock availability').text.strip()\n",
    "            rating = book.find('p', class_='star-rating')['class'][1]\n",
    "\n",
    "            books_data.append({\n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'availability': availability,\n",
    "                'rating': rating\n",
    "            })\n",
    "        return books_data\n",
    "    else:\n",
    "        print(f\"Failed to fetch page, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def scrape_quotes_data():\n",
    "    url = \"http://quotes.toscrape.com/page/1/\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        quote_blocks = soup.find_all('div', class_='quote')  \n",
    "        \n",
    "        quotes_data = []\n",
    "        for quote in quote_blocks:\n",
    "            text = quote.find('span', class_='text').text.strip()\n",
    "            author = quote.find('small', class_='author').text.strip()\n",
    "\n",
    "            quotes_data.append({\n",
    "                'text': text,\n",
    "                'author': author,\n",
    "            })\n",
    "        return quotes_data\n",
    "    else:\n",
    "        print(f\"Failed to fetch page, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def clean_books_data(books_data):\n",
    "    cleaned_data = []\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    for book in books_data:\n",
    "        # Remove non-numeric characters except the decimal point\n",
    "        price_str = re.sub(r'[^\\d.]', '', book['price'])\n",
    "        try:\n",
    "            price = float(price_str)\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert price to float for book: {book['title']}\")\n",
    "            price = None  # Set price to None if conversion fails\n",
    "\n",
    "        # Standardize availability field\n",
    "        availability = book['availability'].replace('\\n', '').strip()\n",
    "        \n",
    "        # Add timestamp metadata\n",
    "        enriched_book = {\n",
    "            'title': book['title'],\n",
    "            'price': price,\n",
    "            'availability': availability,\n",
    "            'rating': book['rating'],\n",
    "            'scrape_timestamp': timestamp\n",
    "        }\n",
    "        cleaned_data.append(enriched_book)\n",
    "    return cleaned_data\n",
    "\n",
    "def clean_quotes_data(quotes_data):\n",
    "    cleaned_data = []\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    for quote in quotes_data:\n",
    "        # Only keep entries with 'text' and 'author' fields\n",
    "        if 'text' in quote and 'author' in quote:\n",
    "            cleaned_quote = {\n",
    "                'text': quote['text'],\n",
    "                'author': quote['author'],\n",
    "                'scrape_timestamp': timestamp\n",
    "            }\n",
    "            cleaned_data.append(cleaned_quote)\n",
    "    return cleaned_data\n",
    "\n",
    "\n",
    "def add_price_category(books_data):\n",
    "    for book in books_data:\n",
    "        if book['price'] < 10:\n",
    "            book['price_category'] = 'cheap'\n",
    "        elif book['price'] < 20:\n",
    "            book['price_category'] = 'moderate'\n",
    "        else:\n",
    "            book['price_category'] = 'expensive'\n",
    "    return books_data\n",
    "\n",
    "def add_sentiment_analysis(quotes_data):\n",
    "    enriched_data = []\n",
    "    for quote in quotes_data:\n",
    "        sentiment = TextBlob(quote['text']).sentiment.polarity  # Sentiment value between -1 and 1\n",
    "        enriched_quote = quote.copy()\n",
    "        enriched_quote['sentiment'] = sentiment\n",
    "        enriched_data.append(enriched_quote)\n",
    "    return enriched_data\n",
    "\n",
    "def save_data_to_minio(data, minio_client, bucket_name, object_name):\n",
    "    csv_data = StringIO()\n",
    "    fieldnames = data[0].keys()\n",
    "    writer = csv.DictWriter(csv_data, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for record in data:\n",
    "        writer.writerow(record)\n",
    "    \n",
    "    csv_data_bytes = BytesIO(csv_data.getvalue().encode('utf-8'))\n",
    "\n",
    "    if not minio_client.bucket_exists(bucket_name):\n",
    "        minio_client.make_bucket(bucket_name)\n",
    "    \n",
    "    minio_client.put_object(\n",
    "        bucket_name, object_name, csv_data_bytes, len(csv_data_bytes.getvalue())\n",
    "    )\n",
    "    print(f\"Data saved successfully as {object_name} in bucket '{bucket_name}'.\")\n",
    "\n",
    "# Bronze level data scraping\n",
    "book_data = scrape_books_data()\n",
    "quote_data = scrape_quotes_data()\n",
    "\n",
    "# Silver level data cleaning and enrichment\n",
    "if book_data:\n",
    "    cleaned_books_data = clean_books_data(book_data)\n",
    "    save_data_to_minio(cleaned_books_data, minio_client, 'silver', f'books_data_silver_{datetime.now().strftime(\"%Y%m%d\")}.csv')\n",
    "\n",
    "if quote_data:\n",
    "    cleaned_quotes_data = clean_quotes_data(quote_data)  # Use the correct function\n",
    "    save_data_to_minio(cleaned_quotes_data, minio_client, 'silver', f'quotes_data_silver_{datetime.now().strftime(\"%Y%m%d\")}.csv')\n",
    "\n",
    "# Gold level data with added analysis\n",
    "if cleaned_books_data:\n",
    "    gold_books_data = add_price_category(cleaned_books_data)\n",
    "    save_data_to_minio(gold_books_data, minio_client, 'gold', f'books_data_gold_{datetime.now().strftime(\"%Y%m%d\")}.csv')\n",
    "\n",
    "if cleaned_quotes_data:\n",
    "    gold_quotes_data = add_sentiment_analysis(cleaned_quotes_data)\n",
    "    save_data_to_minio(gold_quotes_data, minio_client, 'gold', f'quotes_data_gold_{datetime.now().strftime(\"%Y%m%d\")}.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
