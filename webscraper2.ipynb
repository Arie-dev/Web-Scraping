{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Pipeline Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we explained last week, we introduced the concept of a three-layer data pipeline: Bronze, Silver, and Gold. In last week's notebook, we focused on the Bronze layer, where we scraped raw data from a website and stored it in its most basic, unprocessed form in our Minio object storage.\n",
    "\n",
    "Today, we'll continue to build on that foundation and move to the next stages of the pipeline. Specifically, we will:\n",
    "\n",
    "1. Clean and process the data from the Bronze layer to create the Silver layer. This layer represents data that has been transformed and standardized, but it’s still not yet enriched or ready for final analysis.\n",
    "\n",
    "2. Enrich the data for the Gold layer, where we will apply additional transformations such as sentiment analysis to extract more value and insight from the data. This enriched data will be stored and ready for reporting and analysis.\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "- Set up our Minio client and ensure that the appropriate buckets exist for each layer.\n",
    "- Transform the raw data from the Bronze layer to clean and standardized data for the Silver layer.\n",
    "- Apply enrichment techniques, like sentiment analysis, for the Gold layer.\n",
    "- Store the Silver data as Parquet files (for optimized storage and processing) and the Gold data as CSV files (for easy use in reporting or other tools).\n",
    "\n",
    "By the end of this notebook, we will have taken raw, unprocessed data from the Bronze layer and transformed it into clean, enriched data that is stored and ready for further use in downstream analysis or business applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from minio import Minio\n",
    "from datetime import datetime\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import csv\n",
    "from io import StringIO\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup Minio Client\n",
    "In this step, we will set up the Minio client and check if the required buckets for the Bronze, Silver, and Gold layers exist. If they don't exist, we will create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minio client setup completed. Buckets checked/created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def setup_minio_client():\n",
    "    minio_client = Minio('localhost:9000',\n",
    "                         access_key='ROOTUSER',\n",
    "                         secret_key='DATAINCUBATOR',\n",
    "                         secure=False)\n",
    "    # Create buckets if they don't exist\n",
    "    for bucket in ['bronze', 'silver', 'gold']:\n",
    "        if not minio_client.bucket_exists(bucket):\n",
    "            minio_client.make_bucket(bucket)\n",
    "            print(f\"Bucket '{bucket}' created successfully\")\n",
    "    \n",
    "    return minio_client\n",
    "\n",
    "\n",
    "minio_client = setup_minio_client()\n",
    "print(\"Minio client setup completed. Buckets checked/created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output:\n",
    "- Bucket 'bronze' created successfully\n",
    "- Bucket 'silver' created successfully\n",
    "- Bucket 'gold' created successfully\n",
    "- Minio client setup completed. Buckets checked/created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bronze Layer: Scrape Raw Data\n",
    "In this section, we will scrape raw data from a source (e.g., quotes or books) and store it in the Bronze layer. This data is unprocessed and in its raw form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw book data scraped for Bronze layer.\n",
      "[{'title': 'A Light in the Attic', 'price': 'Â£51.77', 'availability': 'In stock', 'rating': 'Three'}, {'title': 'Tipping the Velvet', 'price': 'Â£53.74', 'availability': 'In stock', 'rating': 'One'}, {'title': 'Soumission', 'price': 'Â£50.10', 'availability': 'In stock', 'rating': 'One'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scrape_books_data():\n",
    "    url = \"https://books.toscrape.com/catalogue/page-1.html\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        book_rows = soup.find_all('article', class_='product_pod')  \n",
    "        \n",
    "        books_data = []\n",
    "        for book in book_rows:\n",
    "            title = book.find('h3').find('a')['title']\n",
    "            price = book.find('p', class_='price_color').text.strip()\n",
    "            availability = book.find('p', class_='instock availability').text.strip()\n",
    "            rating = book.find('p', class_='star-rating')['class'][1]\n",
    "\n",
    "            books_data.append({\n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'availability': availability,\n",
    "                'rating': rating\n",
    "            })\n",
    "\n",
    "        return books_data\n",
    "    else:\n",
    "        print(f\"Failed to fetch page, status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "book_data = scrape_books_data()\n",
    "print(\"Raw book data scraped for Bronze layer.\")\n",
    "print(book_data[:3])  # Displaying first 3 items to check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "- Raw book data scraped for Bronze layer.\n",
    "- [{'title': 'A Light in the Attic', 'price': 'Â£51.77', 'availability': 'In stock', 'rating': 'Three'}, {'title': 'Tipping the Velvet', 'price': 'Â£53.74', 'availability': 'In stock', 'rating': 'One'}, {'title': 'Soumission', 'price': 'Â£50.10', 'availability': 'In stock', 'rating': 'One'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw quote data scraped for Bronze layer.\n",
      "[{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein'}, {'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling'}, {'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scrape_quotes_data():\n",
    "    url = \"http://quotes.toscrape.com/page/1/\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        quote_blocks = soup.find_all('div', class_='quote')  \n",
    "        \n",
    "        quotes_data = []\n",
    "        for quote in quote_blocks:\n",
    "            text = quote.find('span', class_='text').text.strip()\n",
    "            author = quote.find('small', class_='author').text.strip()\n",
    "            quotes_data.append({\n",
    "                'text': text,\n",
    "                'author': author,\n",
    "            })\n",
    "\n",
    "        return quotes_data\n",
    "    else:\n",
    "        print(f\"Failed to fetch page, status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "quote_data = scrape_quotes_data()\n",
    "print(\"Raw quote data scraped for Bronze layer.\")\n",
    "print(quote_data[:3])  # Displaying first 3 items to check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Raw quote data scraped for Bronze layer.\n",
    "- [{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein'}, {'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling'}, {'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein'}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Silver Layer: Clean and Process Data\n",
    "\n",
    "In this step, we will clean and standardize the data from the Bronze layer to prepare it for more advanced processing. For instance, we may remove unwanted symbols, standardize certain fields, and handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver layer data cleaned and standardized.\n",
      "[{'title': 'A Light in the Attic', 'price': 51.77, 'availability': 'In stock', 'rating': 'Three', 'scrape_timestamp': '2024-11-06T22:37:18.432391'}, {'title': 'Tipping the Velvet', 'price': 53.74, 'availability': 'In stock', 'rating': 'One', 'scrape_timestamp': '2024-11-06T22:37:18.432391'}, {'title': 'Soumission', 'price': 50.1, 'availability': 'In stock', 'rating': 'One', 'scrape_timestamp': '2024-11-06T22:37:18.432391'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_books_data(books_data):\n",
    "    cleaned_data = []\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    for book in books_data:\n",
    "        # Remove non-numeric characters except the decimal point\n",
    "        price_str = re.sub(r'[^\\d.]', '', book['price'])\n",
    "        try:\n",
    "            price = float(price_str)\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert price to float for book: {book['title']}\")\n",
    "            price = None  # Set price to None if conversion fails\n",
    "\n",
    "        # Standardize availability field\n",
    "        availability = book['availability'].replace('\\n', '').strip()\n",
    "        \n",
    "        # Add timestamp metadata\n",
    "        enriched_book = {\n",
    "            'title': book['title'],\n",
    "            'price': price,\n",
    "            'availability': availability,\n",
    "            'rating': book['rating'],\n",
    "            'scrape_timestamp': timestamp\n",
    "        }\n",
    "        cleaned_data.append(enriched_book)\n",
    "    return cleaned_data\n",
    "\n",
    "cleaned_books_data = clean_books_data(book_data)\n",
    "print(\"Silver layer data cleaned and standardized.\")\n",
    "print(cleaned_books_data[:3])  # Displaying first 3 cleaned items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "- Silver layer data cleaned and standardized.\n",
    "- [{'title': 'A Light in the Attic', 'price': 51.77, 'availability': 'In stock', 'rating': 'Three', 'scrape_timestamp': '2024-11-06T22:09:19.228605'}, {'title': 'Tipping the Velvet', 'price': 53.74, 'availability': 'In stock', 'rating': 'One', 'scrape_timestamp': '2024-11-06T22:09:19.228605'}, {'title': 'Soumission', 'price': 50.1, 'availability': 'In stock', 'rating': 'One', 'scrape_timestamp': '2024-11-06T22:09:19.228605'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver layer data cleaned and standardized.\n",
      "[{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'scrape_timestamp': '2024-11-06T22:37:24.370208'}, {'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'scrape_timestamp': '2024-11-06T22:37:24.370208'}, {'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'scrape_timestamp': '2024-11-06T22:37:24.370208'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_quotes_data(quotes_data):\n",
    "    cleaned_data = []\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    for quote in quotes_data:\n",
    "        # Only keep entries with 'text' and 'author' fields\n",
    "        if 'text' in quote and 'author' in quote:\n",
    "            cleaned_quote = {\n",
    "                'text': quote['text'],\n",
    "                'author': quote['author'],\n",
    "                'scrape_timestamp': timestamp\n",
    "            }\n",
    "            cleaned_data.append(cleaned_quote)\n",
    "    return cleaned_data\n",
    "\n",
    "cleaned_quotes_data = clean_quotes_data(quote_data)\n",
    "print(\"Silver layer data cleaned and standardized.\")\n",
    "print(cleaned_quotes_data[:3])  # Displaying first 3 cleaned items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "- Silver layer data cleaned and standardized.\n",
    "- [{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'scrape_timestamp': '2024-11-06T22:11:29.852715'}, {'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'scrape_timestamp': '2024-11-06T22:11:29.852715'}, {'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'scrape_timestamp': '2024-11-06T22:11:29.852715'}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Silver Layer: Save Cleaned Data to Parquet\n",
    "\n",
    "Now that the data is cleaned, we'll save it to the Silver layer as a Parquet file. This format is efficient for both storage and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully as books_data_silver_20241106.parquet in bucket 'silver'.\n",
      "Data saved successfully as quotes_data_silver_20241106.parquet in bucket 'silver'.\n"
     ]
    }
   ],
   "source": [
    "def save_data_to_minio_parquet(data, minio_client, bucket_name, object_name):\n",
    "    # Convert data to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save DataFrame as Parquet to BytesIO\n",
    "    parquet_data = BytesIO()\n",
    "    df.to_parquet(parquet_data, engine='pyarrow', index=False)\n",
    "    parquet_data.seek(0)  # Reset pointer to the start of the file\n",
    "\n",
    "    if not minio_client.bucket_exists(bucket_name):\n",
    "        minio_client.make_bucket(bucket_name)\n",
    "    \n",
    "    minio_client.put_object(\n",
    "        bucket_name, object_name, parquet_data, len(parquet_data.getvalue())\n",
    "    )\n",
    "    print(f\"Data saved successfully as {object_name} in bucket '{bucket_name}'.\")\n",
    "\n",
    "if book_data:\n",
    "    cleaned_books_data = clean_books_data(book_data)\n",
    "    save_data_to_minio_parquet(cleaned_books_data, minio_client, 'silver', f'books_data_silver_{datetime.now().strftime(\"%Y%m%d\")}.parquet')\n",
    "\n",
    "if quote_data:\n",
    "    cleaned_quotes_data = clean_quotes_data(quote_data)\n",
    "    save_data_to_minio_parquet(cleaned_quotes_data, minio_client, 'silver', f'quotes_data_silver_{datetime.now().strftime(\"%Y%m%d\")}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gold Layer: Enrich Data with Sentiment Analysis and Price Category\n",
    "\n",
    "In this step, we apply sentiment analysis to the Silver layer data to enrich it. This adds additional value to the data and allows us to perform more advanced analytics on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold layer data enriched with sentiment analysis.\n",
      "[{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'scrape_timestamp': '2024-11-06T22:37:31.415431', 'sentiment': 0.0}, {'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'scrape_timestamp': '2024-11-06T22:37:31.415431', 'sentiment': 0.3}, {'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'scrape_timestamp': '2024-11-06T22:37:31.415431', 'sentiment': 0.0037878787878787845}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def add_price_category(books_data):\n",
    "    for book in books_data:\n",
    "        if book['price'] < 10:\n",
    "            book['price_category'] = 'cheap'\n",
    "        elif book['price'] < 20:\n",
    "            book['price_category'] = 'moderate'\n",
    "        else:\n",
    "            book['price_category'] = 'expensive'\n",
    "    return books_data\n",
    "\n",
    "def add_sentiment_analysis(quotes_data):\n",
    "    enriched_data = []\n",
    "    for quote in quotes_data:\n",
    "        sentiment = TextBlob(quote['text']).sentiment.polarity  # Sentiment value between -1 and 1\n",
    "        enriched_quote = quote.copy()\n",
    "        enriched_quote['sentiment'] = sentiment\n",
    "        enriched_data.append(enriched_quote)\n",
    "    return enriched_data\n",
    "\n",
    "\n",
    "gold_books_data = add_price_category(cleaned_books_data)\n",
    "gold_quotes_data = add_sentiment_analysis(cleaned_quotes_data)\n",
    "print(\"Gold layer data enriched with sentiment analysis.\")\n",
    "print(gold_quotes_data[:3])  # Displaying first 3 enriched items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "- Gold layer data enriched with sentiment analysis.\n",
    "- [{'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', 'author': 'Albert Einstein', 'scrape_timestamp': '2024-11-06T22:28:36.654356', 'sentiment': 0.0}, {'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', 'author': 'J.K. Rowling', 'scrape_timestamp': '2024-11-06T22:28:36.654356', 'sentiment': 0.3}, {'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'scrape_timestamp': '2024-11-06T22:28:36.654356', 'sentiment': 0.0037878787878787845}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Gold Layer: Save Enriched Data to CSV\n",
    "Finally, we will save the enriched data to the Gold layer as a CSV file for easy reporting and downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully as books_data_gold_20241106.csv in bucket 'gold'.\n",
      "Data saved successfully as quotes_data_gold_20241106.csv in bucket 'gold'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_data_to_minio_csv(data, minio_client, bucket_name, object_name):\n",
    "    # Convert data to a pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save DataFrame as CSV to BytesIO\n",
    "    csv_data = StringIO()\n",
    "    df.to_csv(csv_data, index=False)\n",
    "    csv_data.seek(0)  # Reset pointer to the start of the file\n",
    "\n",
    "    if not minio_client.bucket_exists(bucket_name):\n",
    "        minio_client.make_bucket(bucket_name)\n",
    "    \n",
    "    minio_client.put_object(\n",
    "        bucket_name, object_name, BytesIO(csv_data.getvalue().encode('utf-8')), len(csv_data.getvalue())\n",
    "    )\n",
    "    print(f\"Data saved successfully as {object_name} in bucket '{bucket_name}'.\")\n",
    "\n",
    "\n",
    "# Gold level data with added analysis (CSV)\n",
    "if cleaned_books_data:\n",
    "    gold_books_data = add_price_category(cleaned_books_data)\n",
    "    save_data_to_minio_csv(gold_books_data, minio_client, 'gold', f'books_data_gold_{datetime.now().strftime(\"%Y%m%d\")}.csv')\n",
    "\n",
    "if cleaned_quotes_data:\n",
    "    gold_quotes_data = add_sentiment_analysis(cleaned_quotes_data)\n",
    "    save_data_to_minio_csv(gold_quotes_data, minio_client, 'gold', f'quotes_data_gold_{datetime.now().strftime(\"%Y%m%d\")}.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
