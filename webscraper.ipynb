{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://github.com/Arie-dev/Web-Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Web Scraping and File Upload to MinIO\n",
    "\n",
    "This script performs web scraping using Beautiful Soup and uploads the scraped data to a MinIO object storage service.\n",
    "\n",
    "##### Dependencies\n",
    "- `BeautifulSoup` from `bs4`: Used for parsing HTML and XML documents.\n",
    "- `requests`: Used for making HTTP requests.\n",
    "- `Minio`: Client for interacting with the MinIO storage service.\n",
    "- `BytesIO`: For handling byte streams in memory.\n",
    "- `datetime`: For working with date and time.\n",
    "\n",
    "##### Setup\n",
    "\n",
    "To use this script, ensure that the following dependencies are installed:\n",
    "```bash\n",
    "pip install beautifulsoup4 requests minio\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Also, make sure you have a running MinIO instance. This script connects to a MinIO server running on `localhost:9000` with the specified access and secret keys.\n",
    "\n",
    "###### Usage\n",
    "\n",
    "1. **Initialize the MinIO client** by calling the `setup_minio_client` function.\n",
    "2. The script checks if the bucket named 'bronze' exists and creates it if it does not.\n",
    "3. You can extend this script by adding functions for web scraping and uploading data to the 'bronze' bucket.\n",
    "\n",
    "##### Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from minio import Minio\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "\n",
    "def setup_minio_client():\n",
    "    minio_client = Minio('localhost:9000',\n",
    "                         access_key='ROOTUSER',\n",
    "                         secret_key='DATAINCUBATOR',\n",
    "                         secure=False)\n",
    "    if not minio_client.bucket_exists('bronze'):\n",
    "        minio_client.make_bucket('bronze')\n",
    "        print(\"Bucket 'bronze' created successfully\")\n",
    "    return minio_client\n",
    "minio_client = setup_minio_client()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scraping Function for Book Data\n",
    "\n",
    "This function scrapes book information from the website [Books to Scrape](https://books.toscrape.com).\n",
    "It retrieves details such as title, price, availability, and rating for each book listed on the first page of the catalog.\n",
    "\n",
    "##### Dependencies\n",
    "- `requests`: Used to make HTTP requests to fetch web pages.\n",
    "- `BeautifulSoup` from `bs4`: Used to parse HTML content.\n",
    "\n",
    "##### Function: `scrape_books_data`\n",
    "\n",
    "##### Description\n",
    "\n",
    "The `scrape_books_data` function sends a GET request to the specified URL, retrieves the HTML content of the page, \n",
    "and parses it to extract book details.\n",
    "\n",
    "##### Returns\n",
    "- `List[Dict[str, str]]`: A list of dictionaries, each containing:\n",
    "  - `title`: The title of the book.\n",
    "  - `price`: The price of the book.\n",
    "  - `availability`: The availability status of the book.\n",
    "  - `rating`: The rating of the book (as a class, e.g., \"One\", \"Two\", \"Three\", \"Four\", \"Five\").\n",
    "\n",
    "If the request fails, the function will print an error message and return `None`.\n",
    "\n",
    "##### Example Usage\n",
    "\n",
    "```python\n",
    "book_data = scrape_books_data()\n",
    "for book in book_data:\n",
    "    print(book)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "outputs": [],
   "source": [
    "def scrape_books_data():\n",
    "    url = \"https://books.toscrape.com/catalogue/page-1.html\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        book_rows = soup.find_all('article', class_='product_pod')  \n",
    "        \n",
    "        books_data = []\n",
    "        for book in book_rows:\n",
    "            title = book.find('h3').find('a')['title']\n",
    "            price = book.find('p', class_='price_color').text.strip()\n",
    "            availability = book.find('p', class_='instock availability').text.strip()\n",
    "            rating = book.find('p', class_='star-rating')['class'][1]\n",
    "\n",
    "            books_data.append({\n",
    "                'title': title,\n",
    "                'price': price,\n",
    "                'availability': availability,\n",
    "                'rating': rating\n",
    "            })\n",
    "\n",
    "        return books_data\n",
    "    else:\n",
    "        print(f\"Failed to fetch page, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "book_data = scrape_books_data()\n",
    "for book in book_data:\n",
    "    print(book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_quotes_data():\n",
    "    url = \"http://quotes.toscrape.com/page/1/\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        quote_blocks = soup.find_all('div', class_='quote')  \n",
    "        \n",
    "        quotes_data = []\n",
    "        for quote in quote_blocks:\n",
    "            text = quote.find('span', class_='text').text.strip()\n",
    "            author = quote.find('small', class_='author').text.strip()\n",
    "           \n",
    "\n",
    "            quotes_data.append({\n",
    "                'text': text,\n",
    "                'author': author,\n",
    "            \n",
    "            })\n",
    "\n",
    "        return quotes_data\n",
    "    else:\n",
    "        print(f\"Failed to fetch page, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "quote_data = scrape_quotes_data()\n",
    "if quote_data:\n",
    "    for quote in quote_data:\n",
    "        print(quote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Save Books Data to MinIO\n",
    "\n",
    "This function saves a list of book data to a MinIO object storage service in CSV format.\n",
    "The CSV file is named with the current date to ensure uniqueness.\n",
    "\n",
    "##### Dependencies\n",
    "- `csv`: Used to write CSV files.\n",
    "- `io.StringIO`: Provides an in-memory string buffer for CSV data.\n",
    "- `datetime`: Used to get the current date for naming the CSV file.\n",
    "- `BytesIO`: Allows the conversion of string data to byte format for uploading.\n",
    "\n",
    "##### Function: `save_books_data_to_minio`\n",
    "\n",
    "###### Description\n",
    "\n",
    "The `save_books_data_to_minio` function takes a list of book data and a MinIO client instance, \n",
    "converts the book data into CSV format, and uploads it to the specified MinIO bucket.\n",
    "\n",
    "###### Parameters\n",
    "- `books_data` (`List[Dict[str, str]]`): A list of dictionaries, where each dictionary contains:\n",
    "  - `title`: The title of the book.\n",
    "  - `price`: The price of the book.\n",
    "  - `availability`: The availability status of the book.\n",
    "  - `rating`: The rating of the book.\n",
    "- `minio_client` (`Minio`): An instance of the MinIO client for interacting with the MinIO server.\n",
    "\n",
    "###### Returns\n",
    "- `None`: The function does not return a value, but it prints a success or error message based on the upload outcome.\n",
    "\n",
    "###### Example Usage\n",
    "\n",
    "```python\n",
    "if book_data:\n",
    "    save_books_data_to_minio(book_data, minio_client)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "def save_books_data_to_minio(books_data, minio_client):\n",
    "    current_datetime = datetime.now().strftime('%Y%m%d')\n",
    "    object_name = f'books_data_{current_datetime}.csv'\n",
    "\n",
    "    csv_data = StringIO()\n",
    "    fieldnames = [\"title\", \"price\", \"availability\", \"rating\"]\n",
    "    writer = csv.DictWriter(csv_data, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for book in books_data:\n",
    "        writer.writerow(book)\n",
    "\n",
    "    csv_data_bytes = BytesIO(csv_data.getvalue().encode('utf-8'))\n",
    "    \n",
    "    try:\n",
    "        minio_client.put_object(\n",
    "            'bronze', object_name, csv_data_bytes, len(csv_data_bytes.getvalue())\n",
    "        )\n",
    "        print(f\"Book data saved successfully as {object_name}\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while uploading to Minio:\", e)\n",
    "\n",
    "if book_data:\n",
    "    save_books_data_to_minio(book_data, minio_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "\n",
    "def save_quotes_data_to_minio(quotes_data, minio_client):\n",
    "    current_datetime = datetime.now().strftime('%Y%m%d')\n",
    "    object_name = f'quotes_data_{current_datetime}.csv'\n",
    "\n",
    "    csv_data = StringIO()\n",
    "    fieldnames = [\"text\", \"author\"]\n",
    "    writer = csv.DictWriter(csv_data, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for quote in quotes_data:\n",
    "        writer.writerow(quote)\n",
    "\n",
    "\n",
    "    csv_data_bytes = BytesIO(csv_data.getvalue().encode('utf-8'))\n",
    "    try:\n",
    "        \n",
    "        minio_client.put_object(\n",
    "            'bronze', object_name, csv_data_bytes, len(csv_data_bytes.getvalue())\n",
    "        )\n",
    "        print(f\"Quotes data saved successfully as {object_name}\")\n",
    "    except S3Error as e:\n",
    "        print(\"An error occurred while uploading to Minio:\", e)\n",
    "\n",
    "\n",
    "if quote_data:\n",
    "    save_quotes_data_to_minio(quote_data, minio_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's your turn\n",
    "\n",
    "The website \"Quotes to Scrape\" features a collection of famous quotes from notable authors, thinkers, and celebrities. Each quote is accompanied by relevant tags, allowing users to explore various themes such as life, love, success, and humor. Notable figures like Albert Einstein, J.K. Rowling, and Jane Austen are featured.\n",
    "\n",
    "You can browse more quotes on the website [here](https://quotes.toscrape.com).\n",
    "\n",
    "#### Its scraping time\n",
    "\n",
    "Try scraping all the quotes and authors from the quotes on the first page. Save it as a csv into a bucket on MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://quotes.toscrape.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About Medallion Architecture\n",
    "\n",
    "Medallion Architecture is a data architecture pattern commonly used in modern data engineering, particularly in cloud platforms like Databricks or in oure case miniodb. It aims to organize data into different quality levels (or layers), enabling better data management, governance, and access. The architecture is typically divided into **three layers**, symbolized by three medals:\n",
    "\n",
    "###### 1. **Bronze Layer (Raw Data)**\n",
    "\n",
    "- **Purpose**: The Bronze layer stores raw, unprocessed data.\n",
    "- **Characteristics**: Data is ingested in its original form without much transformation. This can include structured, semi-structured, or unstructured data.\n",
    "- **Typical Sources**: This layer includes logs, clickstreams, and any other data from various sources such as IoT devices, APIs, databases, or files.\n",
    "- **Advantages**: \n",
    "  - Acts as the raw historical record of all data.\n",
    "  - Useful for reprocessing in case of errors or when new transformations are needed.\n",
    "\n",
    "###### 2. **Silver Layer (Cleaned Data)**\n",
    "\n",
    "- **Purpose**: The Silver layer refines the raw data.\n",
    "- **Characteristics**: Data is filtered, cleaned, and enriched with additional attributes or metadata. Business logic and validation rules are often applied here.\n",
    "- **Transformations**:\n",
    "  - Handling missing values\n",
    "  - Normalizing data formats\n",
    "  - Data joins or enrichments from other sources\n",
    "- **Usage**: This layer is ideal for reporting, analytics, and as input for machine learning models.\n",
    "\n",
    "###### 3. **Gold Layer (Business-Level Data)**\n",
    "\n",
    "- **Purpose**: The Gold layer contains high-quality, curated datasets that are ready for business consumption.\n",
    "- **Characteristics**: This data is fully processed and optimized for specific use cases, such as analytics dashboards or data marts.\n",
    "- **Optimizations**: Aggregations, computations, and business logic are applied to make the data fit for direct consumption by business users or applications.\n",
    "- **Benefits**:\n",
    "  - Optimized for performance (e.g., querying in BI tools).\n",
    "  - Ensures data accuracy and business relevance.\n",
    "\n",
    "\n",
    "links:\n",
    "\n",
    "- https://www.databricks.com/glossary/medallion-architecture\n",
    "- https://dataengineering.wiki/Concepts/Medallion+Architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
