# Use the official OpenJDK image as the base for running Spark
FROM openjdk:11

# Install Python and pip
RUN apt-get update && apt-get install -y python3 python3-pip && \
    apt-get clean

# Install PySpark
RUN pip3 install pyspark

# Set the working directory
WORKDIR /app

# Copy the PySpark script and any necessary files into the container
COPY wordcount.py /app/wordcount.py
COPY data /app/data

# Expose any necessary ports (for Spark UI, if needed)
EXPOSE 4040

# Set the command to execute the PySpark script
CMD ["python3", "/app/wordcount.py"]
